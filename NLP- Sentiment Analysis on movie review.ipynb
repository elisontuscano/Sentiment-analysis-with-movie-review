{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Movie review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "# LIbrary to Clean the texts\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everyone involved with this project should be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What the movie The 60s really represents (to t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you would like to see a film of different k...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Back when musicals weren't showcases for chore...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I figured that it's about time I let this one ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  Everyone involved with this project should be ...  0\n",
       "1  What the movie The 60s really represents (to t...  1\n",
       "2  If you would like to see a film of different k...  1\n",
       "3  Back when musicals weren't showcases for chore...  1\n",
       "4  I figured that it's about time I let this one ...  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=[]\n",
    "for filename in glob.glob(os.path.join('train/pos/', '*.txt')):\n",
    "    f = open(filename, 'r')\n",
    "    content = f.read()\n",
    "    df.append([content,1]) #1 stands for positive review\n",
    "    \n",
    "for filename in glob.glob(os.path.join('train/neg/', '*.txt')):\n",
    "    f = open(filename, 'r')\n",
    "    content = f.read()\n",
    "    df.append([content,0]) #0 stands for negative review\n",
    "    \n",
    "train=pd.DataFrame(df)\n",
    "train=train.sample(frac=1).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A suprisingly good film considering the circum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie was so poorly acted. What was with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To my eternal shame, I've never seen a silent ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My yardstick for measuring a movie's watch-abi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie was the worst movie I've ever seen....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  A suprisingly good film considering the circum...  1\n",
       "1  This movie was so poorly acted. What was with ...  0\n",
       "2  To my eternal shame, I've never seen a silent ...  1\n",
       "3  My yardstick for measuring a movie's watch-abi...  1\n",
       "4  This movie was the worst movie I've ever seen....  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=[]\n",
    "for filename in glob.glob(os.path.join('test/pos/', '*.txt')):\n",
    "    f = open(filename, 'r')\n",
    "    content = f.read()\n",
    "    df.append([content,1]) #1 stands for positive review\n",
    "    \n",
    "for filename in glob.glob(os.path.join('test/neg/', '*.txt')):\n",
    "    f = open(filename, 'r')\n",
    "    content = f.read()\n",
    "    df.append([content,0]) #0 stands for negative review\n",
    "    \n",
    "test=pd.DataFrame(df)\n",
    "test=test.sample(frac=1).reset_index(drop=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags from a string\"\"\"\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def getCleanReview(review):\n",
    "    review = remove_html_tags(review)\n",
    "    #only keep alphabets remove rest\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    #turn all reviews into lowercase\n",
    "    review = review.lower()\n",
    "    #remove stopwords and do stemming\n",
    "    #review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    #Lemmatize and merge the review together after making all the changes\n",
    "    #review = ' '.join([lemmatizer.lemmatize(word) for word in review])\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.iloc[:,0].values\n",
    "Y_train=train.iloc[:,1].values\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i]=getCleanReview(X_train[i])\n",
    "    \n",
    "#clean X_test as well \n",
    "X_test=test.iloc[:,0].values\n",
    "Y_test=test.iloc[:,1].values\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    X_test[i]=getCleanReview(X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74218"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq={}\n",
    "for review in X_train:\n",
    "    words=review.split()\n",
    "    for word in words:\n",
    "        if word not in wordfreq.keys():\n",
    "            wordfreq[word]=1\n",
    "        else:\n",
    "            wordfreq[word]+=1\n",
    "len(wordfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28757"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove words with occurance less than 5 and remove stopwords\n",
    "repeat=[]\n",
    "for i in wordfreq.keys():\n",
    "    if wordfreq[i] <5 :\n",
    "        repeat.append(i)\n",
    "    \n",
    "for i in repeat:\n",
    "    del wordfreq[i]\n",
    "\n",
    "len(wordfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the less frequent words from out training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_words(dataset,wordfreq):\n",
    "    for index ,review in enumerate(dataset):\n",
    "        cleanreview=[]\n",
    "        for word in review.split():\n",
    "            if word in wordfreq.keys():\n",
    "                cleanreview.append(word)\n",
    "        cleanreview=' '.join(cleanreview)\n",
    "        dataset[index]=cleanreview\n",
    "    return dataset\n",
    "\n",
    "X_train=remove_extra_words(X_train,wordfreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions required for naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_count(X,wordfreq):\n",
    "    wordcount={}\n",
    "    for word in wordfreq.keys():\n",
    "        count=0\n",
    "        for review in X:\n",
    "            if word in review:\n",
    "                count+=1\n",
    "        wordcount[word]=count\n",
    "    return wordcount\n",
    "\n",
    "wordcount=Word_count(X_train,wordfreq)\n",
    "\n",
    "#occurance of the word in positive document\n",
    "def Word_positive(X,Y,wordfreq):\n",
    "    wordpositive={}\n",
    "    for word in wordfreq.keys():\n",
    "        count=0\n",
    "        for index,review in enumerate(X):\n",
    "            if word in review and Y[index]==1:\n",
    "                count+=1\n",
    "        wordpositive[word]=count\n",
    "    return wordpositive\n",
    "\n",
    "wordpositive=Word_positive(X_train,Y_train,wordfreq)\n",
    "\n",
    "#occurance of the word in negative document\n",
    "def Word_negative(X,Y,wordfreq):\n",
    "    wordnegative={}\n",
    "    for word in wordfreq.keys():\n",
    "        count=0\n",
    "        for index,review in enumerate(X):\n",
    "            if word in review and Y[index]==0:\n",
    "                count+=1\n",
    "        wordnegative[word]=count\n",
    "    return wordnegative\n",
    "\n",
    "wordnegative=Word_negative(X_train,Y_train,wordfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_sentiment(Y ,sentiment):\n",
    "    length=0\n",
    "    for i in Y:\n",
    "        if i == sentiment:\n",
    "            length+=1\n",
    "    return length\n",
    "\n",
    "def conditional_probability(X,Y,word,sentiment,length):\n",
    "    if sentiment ==1:\n",
    "        count=0 if word not in wordpositive.keys() else wordpositive[word]\n",
    "    else:\n",
    "        count=0 if word not in wordnegative.keys() else wordnegative[word]\n",
    "    return count/length\n",
    "\n",
    "def get_sentiment_probability(Y,sentiment):\n",
    "    count=0\n",
    "    for i in Y:\n",
    "        if i==sentiment:\n",
    "            count+=1\n",
    "    return count/len(Y)\n",
    "\n",
    "def calculateBayes(X,Y,word,sentiment,length):\n",
    "    one=conditional_probability(X,Y,word,sentiment,length)\n",
    "    two=length/len(Y) #probability of the sentiment\n",
    "    three=calculate_probability_occurance(X,word)\n",
    "    count=wordcount[word] if word in wordcount.keys() else 2\n",
    "    return  (((one*two)+1)/(three+count))\n",
    "\n",
    "def reviewSentiment(X,Y,review,sentiment):\n",
    "    sum=1\n",
    "    length = total_sentiment(Y_train ,1)\n",
    "    for word in review.split():\n",
    "        prob = calculateBayes(X,Y,word,sentiment,length)\n",
    "        sum *= prob\n",
    "    return sum\n",
    "\n",
    "def naiveBayes(X,Y,review):\n",
    "    #check if review sentiment is positive\n",
    "    positive =reviewSentiment(X,Y,review,1)\n",
    "    #check if review sentiment is negative\n",
    "    negative =reviewSentiment(X,Y,review,0)\n",
    "    if positive > negative:\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "    \n",
    "def naiveBayes_onWhole(X,Y,x_test):\n",
    "    ypred=[]\n",
    "    for review in x_test:\n",
    "        pred=naiveBayes(X,Y,review)\n",
    "        ypred.append(pred)\n",
    "    return ypred\n",
    "\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "def calculate_probability_occurance(dataset,word):\n",
    "    count= 0 if word not in wordcount.keys() else wordcount[word]\n",
    "    return count/len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate accuracy on test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=naiveBayes_onWhole(X_train,Y_train,X_test)\n",
    "score=accuracy_metric(Y_test, y_pred)\n",
    "print('Accuracy on unclean development set : {} %'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Naive Bayes library from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train.iloc[:,0].values\n",
    "Y_train=train.iloc[:,1].values\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i]=getCleanReview(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up tfidfvectorizor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizor=TfidfVectorizer(stop_words='english', max_df=0.7,max_features=10000)\n",
    "\n",
    "#fit and transform train and test set\n",
    "tfidf_train=tfidf_vectorizor.fit_transform(X_train).toarray()\n",
    "tfidf_test=tfidf_vectorizor.transform(X_test).toarray()\n",
    "tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7806399999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "NaiveClassifier = GaussianNB()\n",
    "NaiveClassifier.fit(tfidf_train, Y_train)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = NaiveClassifier, X = tfidf_train, y = Y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
